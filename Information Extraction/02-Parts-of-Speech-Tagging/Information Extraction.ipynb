{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Links\n",
    "Information extraction \n",
    "<ul>\n",
    "    <li><a href=\"https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da\">NLTK</a></li>\n",
    "    <li><a href=\"https://www.analyticsvidhya.com/blog/2020/06/nlp-project-information-extraction/\">Finding Patterns</a></li>\n",
    "    <li><a href=\"https://www.analyticsvidhya.com/blog/2019/09/introduction-information-extraction-python-spacy/?utm_source=blog&utm_medium=nlp-project-information-extraction\">Hearst Patterns</a></li>\n",
    "    <li><a href=\"https://medium.com/@ashiqgiga07/rule-based-matching-with-spacy-295b76ca2b68\">Rule-Based Matching</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-49094150dda4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# perform standard imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# These are imported as part of the API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprefer_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_gpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\thinc\\neural\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0municode_literals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_classes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\thinc\\neural\\_classes\\model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNumpyOps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCupyOps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\thinc\\neural\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_decay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "# perform standard imports\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Part of Speech (POS)\n",
    "There are eight different POS in the English language: noun, pronoun, verb, adjective, adverb, preposition, conjunction, and intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The        DET      DT     determiner\n",
      "children   NOUN     NNS    noun, plural\n",
      "love       VERB     VBP    verb, non-3rd person singular present\n",
      "cream      NOUN     NN     noun, singular or mass\n",
      "biscuits   NOUN     NNS    noun, plural\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm') # pretrained english dictionary/thesaurus statistical model\n",
    "\n",
    "# create a simple Doc object\n",
    "doc = nlp(u\"The children love cream biscuits\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text:{10}} {token.pos_:{8}} {token.tag_:{6}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "children\n",
      "cream\n",
      "biscuits\n"
     ]
    }
   ],
   "source": [
    "# extract nouns\n",
    "for token in doc:\n",
    "    # check token pos\n",
    "    if token.pos_== 'NOUN':\n",
    "        # print token\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse-grained Part-of-speech Tags\n",
    "Every token is assigned a POS Tag from the following list:\n",
    "\n",
    "\n",
    "<table><tr><th>POS</th><th>DESCRIPTION</th><th>EXAMPLES</th></tr>\n",
    "    \n",
    "<tr><td>ADJ</td><td>adjective</td><td>*big, old, green, incomprehensible, first*</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>*in, to, during*</td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>*very, tomorrow, down, where, there*</td></tr>\n",
    "<tr><td>AUX</td><td>auxiliary</td><td>*is, has (done), will (do), should (do)*</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>CCONJ</td><td>coordinating conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>*a, an, the*</td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>*psst, ouch, bravo, hello*</td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>*girl, cat, tree, air, beauty*</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>*1, 2017, one, seventy-seven, IV, MMXIV*</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>*'s, not,*</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>*I, you, he, she, myself, themselves, somebody*</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>*Mary, John, London, NATO, HBO*</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>*., (, ), ?*</td></tr>\n",
    "<tr><td>SCONJ</td><td>subordinating conjunction</td><td>*if, while, that*</td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>*$, %, ¬ß, ¬©, +, ‚àí, √ó, √∑, =, :), üòù*</td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>*run, runs, running, eat, ate, eating*</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>*sfpksdpsxmsa*</td></tr>\n",
    "<tr><td>SPACE</td><td>space</td></tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Fine-grained Part-of-speech Tags\n",
    "Tokens are subsequently given a fine-grained tag as determined by morphology:\n",
    "<table>\n",
    "<tr><th>POS</th><th>Description</th><th>Fine-grained Tag</th><th>Description</th><th>Morphology</th></tr>\n",
    "<tr><td>ADJ</td><td>adjective</td><td>AFX</td><td>affix</td><td>Hyph=yes</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJ</td><td>adjective</td><td>Degree=pos</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJR</td><td>adjective, comparative</td><td>Degree=comp</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJS</td><td>adjective, superlative</td><td>Degree=sup</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>PDT</td><td>predeterminer</td><td>AdjType=pdt PronType=prn</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>PRP\\$</td><td>pronoun, possessive</td><td>PronType=prs Poss=yes</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>WDT</td><td>wh-determiner</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>WP\\$</td><td>wh-pronoun, possessive</td><td>Poss=yes PronType=int rel</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>IN</td><td>conjunction, subordinating or preposition</td><td></td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>EX</td><td>existential there</td><td>AdvType=ex</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RB</td><td>adverb</td><td>Degree=pos</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RBR</td><td>adverb, comparative</td><td>Degree=comp</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RBS</td><td>adverb, superlative</td><td>Degree=sup</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>WRB</td><td>wh-adverb</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>CC</td><td>conjunction, coordinating</td><td>ConjType=coor</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>DT</td><td>determiner</td><td></td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>UH</td><td>interjection</td><td></td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>NN</td><td>noun, singular or mass</td><td>Number=sing</td></tr>\n",
    "<tr><td>NOUN</td><td></td><td>NNS</td><td>noun, plural</td><td>Number=plur</td></tr>\n",
    "<tr><td>NOUN</td><td></td><td>WP</td><td>wh-pronoun, personal</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>CD</td><td>cardinal number</td><td>NumType=card</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>POS</td><td>possessive ending</td><td>Poss=yes</td></tr>\n",
    "<tr><td>PART</td><td></td><td>RP</td><td>adverb, particle</td><td></td></tr>\n",
    "<tr><td>PART</td><td></td><td>TO</td><td>infinitival to</td><td>PartType=inf VerbForm=inf</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>PRP</td><td>pronoun, personal</td><td>PronType=prs</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>NNP</td><td>noun, proper singular</td><td>NounType=prop Number=sign</td></tr>\n",
    "<tr><td>PROPN</td><td></td><td>NNPS</td><td>noun, proper plural</td><td>NounType=prop Number=plur</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>-LRB-</td><td>left round bracket</td><td>PunctType=brck PunctSide=ini</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>-RRB-</td><td>right round bracket</td><td>PunctType=brck PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>,</td><td>punctuation mark, comma</td><td>PunctType=comm</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>:</td><td>punctuation mark, colon or ellipsis</td><td></td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>.</td><td>punctuation mark, sentence closer</td><td>PunctType=peri</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>''</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>\"\"</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>``</td><td>opening quotation mark</td><td>PunctType=quot PunctSide=ini</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>HYPH</td><td>punctuation mark, hyphen</td><td>PunctType=dash</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>LS</td><td>list item marker</td><td>NumType=ord</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>NFP</td><td>superfluous punctuation</td><td></td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>#</td><td>symbol, number sign</td><td>SymType=numbersign</td></tr>\n",
    "<tr><td>SYM</td><td></td><td>\\$</td><td>symbol, currency</td><td>SymType=currency</td></tr>\n",
    "<tr><td>SYM</td><td></td><td>SYM</td><td>symbol</td><td></td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>BES</td><td>auxiliary \"be\"</td><td></td></tr>\n",
    "<tr><td>VERB</td><td></td><td>HVS</td><td>forms of \"have\"</td><td></td></tr>\n",
    "<tr><td>VERB</td><td></td><td>MD</td><td>verb, modal auxiliary</td><td>VerbType=mod</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VB</td><td>verb, base form</td><td>VerbForm=inf</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBD</td><td>verb, past tense</td><td>VerbForm=fin Tense=past</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBG</td><td>verb, gerund or present participle</td><td>VerbForm=part Tense=pres Aspect=prog</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBN</td><td>verb, past participle</td><td>VerbForm=part Tense=past Aspect=perf</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBP</td><td>verb, non-3rd person singular present</td><td>VerbForm=fin Tense=pres</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBZ</td><td>verb, 3rd person singular present</td><td>VerbForm=fin Tense=pres Number=sing Person=3</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>ADD</td><td>email</td><td></td></tr>\n",
    "<tr><td>X</td><td></td><td>FW</td><td>foreign word</td><td>Foreign=yes</td></tr>\n",
    "<tr><td>X</td><td></td><td>GW</td><td>additional word in multi-word expression</td><td></td></tr>\n",
    "<tr><td>X</td><td></td><td>XX</td><td>unknown</td><td></td></tr>\n",
    "<tr><td>SPACE</td><td>space</td><td>_SP</td><td>space</td><td></td></tr>\n",
    "<tr><td></td><td></td><td>NIL</td><td>missing tag</td><td></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Graph\n",
    "The arrows carry a lot of significance:\n",
    "<ul>\n",
    "    <li>The arrowhead points to the words that are dependent on the word pointed by the origin of the arrow</li>\n",
    "    <li>The former is referred to as the child node of the latter. For example, ‚Äúchildren‚Äù is the child node of ‚Äúlove‚Äù</li>\n",
    "    <li>The word which has no incoming arrow is called the root node of the sentence</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"d87204d376624228bfcbff953c92899e-0\" class=\"displacy\" width=\"600\" height=\"247.0\" direction=\"ltr\" style=\"max-width: none; height: 247.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">children</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">love</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">cream</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">biscuits</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d87204d376624228bfcbff953c92899e-0-0\" stroke-width=\"2px\" d=\"M70,112.0 C70,57.0 155.0,57.0 155.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d87204d376624228bfcbff953c92899e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,114.0 L62,102.0 78,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d87204d376624228bfcbff953c92899e-0-1\" stroke-width=\"2px\" d=\"M180,112.0 C180,57.0 265.0,57.0 265.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d87204d376624228bfcbff953c92899e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,114.0 L172,102.0 188,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d87204d376624228bfcbff953c92899e-0-2\" stroke-width=\"2px\" d=\"M400,112.0 C400,57.0 485.0,57.0 485.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d87204d376624228bfcbff953c92899e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,114.0 L392,102.0 408,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d87204d376624228bfcbff953c92899e-0-3\" stroke-width=\"2px\" d=\"M290,112.0 C290,2.0 490.0,2.0 490.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d87204d376624228bfcbff953c92899e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M490.0,114.0 L498.0,102.0 482.0,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# render the dependency parse immediately inside Jupyter:\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 110})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "children\n",
      "biscuits\n"
     ]
    }
   ],
   "source": [
    "# extract subject and object\n",
    "for token in doc:\n",
    "    # extract subject\n",
    "    if (token.dep_=='nsubj'):\n",
    "        print(token.text)\n",
    "    # extract object\n",
    "    elif (token.dep_=='dobj'):\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Named Entity Recognition (NER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vietnam - GPE - Countries, cities, states\n",
      "Ferrari - ORG - Companies, agencies, institutions, etc.\n",
      "the last quarter - DATE - Absolute or relative dates or periods\n",
      "Apple - ORG - Companies, agencies, institutions, etc.\n",
      "nearly 20 thousand - CARDINAL - Numerals that do not fall under another type\n",
      "iPods - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "$6 million - MONEY - Monetary values, including unit\n",
      "Sony - ORG - Companies, agencies, institutions, etc.\n",
      "only 7 thousand - CARDINAL - Numerals that do not fall under another type\n",
      "Walkman - NORP - Nationalities or religious or political groups\n",
      "1 Jan of every year - DATE - Absolute or relative dates or periods\n",
      "one credit year - DATE - Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm') # pretrained english dictionary/thesaurus statistical model\n",
    "\n",
    "# function to display basic entity info:\n",
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('No named entities found.')\n",
    "\n",
    "doc = nlp(u'GDP in developing countries such as Vietnam will continue growing at a high rate.'\n",
    "            u'Fruits such as apples. '\n",
    "            u'Cars such as Ferrari. '\n",
    "            u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million. '\n",
    "            u'By contrast, Sony sold only 7 thousand Walkman music players. '\n",
    "            u'credits will be allocated on 1 Jan of every year. '\n",
    "            u'carried forward up to one credit year. ')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER Tags\n",
    "Tags are accessible through the `.label_` property of an entity.\n",
    "<table>\n",
    "<tr><th>TYPE</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n",
    "<tr><td>`PERSON`</td><td>People, including fictional.</td><td>*Fred Flintstone*</td></tr>\n",
    "<tr><td>`NORP`</td><td>Nationalities or religious or political groups.</td><td>*The Republican Party*</td></tr>\n",
    "<tr><td>`FAC`</td><td>Buildings, airports, highways, bridges, etc.</td><td>*Logan International Airport, The Golden Gate*</td></tr>\n",
    "<tr><td>`ORG`</td><td>Companies, agencies, institutions, etc.</td><td>*Microsoft, FBI, MIT*</td></tr>\n",
    "<tr><td>`GPE`</td><td>Countries, cities, states.</td><td>*France, UAR, Chicago, Idaho*</td></tr>\n",
    "<tr><td>`LOC`</td><td>Non-GPE locations, mountain ranges, bodies of water.</td><td>*Europe, Nile River, Midwest*</td></tr>\n",
    "<tr><td>`PRODUCT`</td><td>Objects, vehicles, foods, etc. (Not services.)</td><td>*Formula 1*</td></tr>\n",
    "<tr><td>`EVENT`</td><td>Named hurricanes, battles, wars, sports events, etc.</td><td>*Olympic Games*</td></tr>\n",
    "<tr><td>`WORK_OF_ART`</td><td>Titles of books, songs, etc.</td><td>*The Mona Lisa*</td></tr>\n",
    "<tr><td>`LAW`</td><td>Named documents made into laws.</td><td>*Roe v. Wade*</td></tr>\n",
    "<tr><td>`LANGUAGE`</td><td>Any named language.</td><td>*English*</td></tr>\n",
    "<tr><td>`DATE`</td><td>Absolute or relative dates or periods.</td><td>*20 July 1969*</td></tr>\n",
    "<tr><td>`TIME`</td><td>Times smaller than a day.</td><td>*Four hours*</td></tr>\n",
    "<tr><td>`PERCENT`</td><td>Percentage, including \"%\".</td><td>*Eighty percent*</td></tr>\n",
    "<tr><td>`MONEY`</td><td>Monetary values, including unit.</td><td>*Twenty Cents*</td></tr>\n",
    "<tr><td>`QUANTITY`</td><td>Measurements, as of weight or distance.</td><td>*Several kilometers, 55kg*</td></tr>\n",
    "<tr><td>`ORDINAL`</td><td>\"first\", \"second\", etc.</td><td>*9th, Ninth*</td></tr>\n",
    "<tr><td>`CARDINAL`</td><td>Numerals that do not fall under another type.</td><td>*2, Two, Fifty-two*</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">GDP in developing countries such as \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Vietnam\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " will continue growing at a high rate.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fruits such as apples.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Cars such as \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ferrari\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPods\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">By contrast, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sony\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    only 7 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Walkman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " music players.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">credits will be allocated on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1 Jan of every year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">carried forward up to \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one credit year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm') # pretrained english dictionary/thesaurus statistical model\n",
    "\n",
    "doc = nlp(u'GDP in developing countries such as Vietnam will continue growing at a high rate.'\n",
    "            u'Fruits such as apples. '\n",
    "            u'Cars such as Ferrari. '\n",
    "            u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million. '\n",
    "            u'By contrast, Sony sold only 7 thousand Walkman music players. '\n",
    "            u'credits will be allocated on 1 Jan of every year. '\n",
    "            u'carried forward up to one credit year. ')\n",
    "\n",
    "for sent in doc.sents:\n",
    "    docx = nlp(sent.text)\n",
    "    if docx.ents:\n",
    "        displacy.render(docx, style='ent', jupyter=True)\n",
    "    else:\n",
    "        print(docx.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pattern Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDP        PROPN    nsubj  noun, proper singular\n",
      "in         ADP      prep   conjunction, subordinating or preposition\n",
      "developing VERB     amod   verb, gerund or present participle\n",
      "countries  NOUN     pobj   noun, plural\n",
      "such       ADJ      amod   adjective\n",
      "as         SCONJ    prep   conjunction, subordinating or preposition\n",
      "Vietnam    PROPN    pobj   noun, proper singular\n",
      "will       VERB     aux    verb, modal auxiliary\n",
      "continue   VERB     ROOT   verb, base form\n",
      "growing    VERB     xcomp  verb, gerund or present participle\n",
      "at         ADP      prep   conjunction, subordinating or preposition\n",
      "a          DET      det    determiner\n",
      "high       ADJ      amod   adjective\n",
      "rate       NOUN     pobj   noun, singular or mass\n",
      ".          PUNCT    punct  punctuation mark, sentence closer\n",
      "Fruits     NOUN     ROOT   noun, plural\n",
      "such       ADJ      amod   adjective\n",
      "as         SCONJ    prep   conjunction, subordinating or preposition\n",
      "apples     NOUN     pobj   noun, plural\n",
      ".          PUNCT    punct  punctuation mark, sentence closer\n",
      "Cars       NOUN     ROOT   noun, plural\n",
      "such       ADJ      amod   adjective\n",
      "as         SCONJ    prep   conjunction, subordinating or preposition\n",
      "Ferrari    PROPN    pobj   noun, proper singular\n",
      ".          PUNCT    punct  punctuation mark, sentence closer\n",
      "Over       ADP      prep   conjunction, subordinating or preposition\n",
      "the        DET      det    determiner\n",
      "last       ADJ      amod   adjective\n",
      "quarter    NOUN     pobj   noun, singular or mass\n",
      "Apple      PROPN    nsubj  noun, proper singular\n",
      "sold       VERB     ROOT   verb, past tense\n",
      "nearly     ADV      advmod adverb\n",
      "20         NUM      compound cardinal number\n",
      "thousand   NUM      nummod cardinal number\n",
      "iPods      PROPN    dobj   noun, proper plural\n",
      "for        ADP      prep   conjunction, subordinating or preposition\n",
      "a          DET      det    determiner\n",
      "profit     NOUN     pobj   noun, singular or mass\n",
      "of         ADP      prep   conjunction, subordinating or preposition\n",
      "$          SYM      quantmod symbol, currency\n",
      "6          NUM      compound cardinal number\n",
      "million    NUM      pobj   cardinal number\n",
      ".          PUNCT    punct  punctuation mark, sentence closer\n",
      "By         ADP      prep   conjunction, subordinating or preposition\n",
      "contrast   NOUN     pobj   noun, singular or mass\n",
      ",          PUNCT    punct  punctuation mark, comma\n",
      "Sony       PROPN    nsubj  noun, proper singular\n",
      "sold       VERB     ROOT   verb, past tense\n",
      "only       ADV      advmod adverb\n",
      "7          NUM      compound cardinal number\n",
      "thousand   NUM      nummod cardinal number\n",
      "Walkman    PROPN    compound noun, proper singular\n",
      "music      NOUN     compound noun, singular or mass\n",
      "players    NOUN     dobj   noun, plural\n",
      ".          PUNCT    punct  punctuation mark, sentence closer\n",
      "credits    NOUN     nsubjpass noun, plural\n",
      "will       VERB     aux    verb, modal auxiliary\n",
      "be         AUX      auxpass verb, base form\n",
      "allocated  VERB     ROOT   verb, past participle\n",
      "on         ADP      prep   conjunction, subordinating or preposition\n",
      "1          NUM      nummod cardinal number\n",
      "Jan        PROPN    pobj   noun, proper singular\n",
      "of         ADP      prep   conjunction, subordinating or preposition\n",
      "every      DET      det    determiner\n",
      "year       NOUN     pobj   noun, singular or mass\n",
      ".          PUNCT    punct  punctuation mark, sentence closer\n",
      "carried    VERB     ROOT   verb, past participle\n",
      "forward    ADV      advmod adverb\n",
      "up         ADP      prep   conjunction, subordinating or preposition\n",
      "to         ADP      prep   conjunction, subordinating or preposition\n",
      "one        NUM      nummod cardinal number\n",
      "credit     NOUN     compound noun, singular or mass\n",
      "year       NOUN     pobj   noun, singular or mass\n",
      ".          PUNCT    punct  punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "# print token, dependency, POS tag \n",
    "for token in doc:\n",
    "    print(f'{token.text:{10}} {token.pos_:{8}} {token.dep_:{6}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ferrari\n",
      "Apple\n",
      "Sony\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm') # pretrained english dictionary/thesaurus statistical model\n",
    "\n",
    "# create a spaCy object \n",
    "doc = nlp(u'GDP in developing countries such as Vietnam will continue growing at a high rate.'\n",
    "            u'Fruits such as apples. '\n",
    "            u'Cars such as Ferrari. '\n",
    "            u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million. '\n",
    "            u'By contrast, Sony sold only 7 thousand Walkman music players. '\n",
    "            u'credits will be allocated on 1 Jan of every year. '\n",
    "            u'carried forward up to one credit year. ')\n",
    "\n",
    "# Matcher class object\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# define the pattern e.g. Hearst Pattern\n",
    "# the key ‚ÄòOP‚Äô: ‚Äò?‚Äô in the pattern means that the modifier ('amod') can occur once or not at all.\n",
    "'''\n",
    "pattern = [#{'DEP':'amod', 'OP':\"?\"}, # adjectival modifier\n",
    "           {'POS':'NOUN'},\n",
    "           {'LOWER': 'such'},\n",
    "           {'LOWER': 'as'},\n",
    "           {'POS': 'PROPN'}]\n",
    "'''\n",
    "pattern = [{'ENT_TYPE':'ORG'}]\n",
    "\n",
    "matcher.add(\"matching_1\", None, pattern)\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match in matches:\n",
    "    span = doc[match[1]:match[2]] \n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Customized Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('apples', 'PRODUCT')]\n",
      "\n",
      "\n",
      "GDP in developing countries such as Vietnam will continue growing at a high rate.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Fruits such as \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    apples\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cars such as Ferrari.\n",
      "Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.\n",
      "By contrast, Sony sold only 7 thousand Walkman music players.\n",
      "credits will be allocated on 1 Jan of every year.\n",
      "carried forward up to one credit year.\n"
     ]
    }
   ],
   "source": [
    "nlp = English() # empty english dictionary/thesaurus statistical model\n",
    "\n",
    "# instantiate an object of EntityRuler class\n",
    "ruler = EntityRuler(nlp)\n",
    "\n",
    "# define the pattern \n",
    "pattern = [{\"label\": \"PRODUCT\", \"pattern\": [{\"lower\": \"apples\"}]}]\n",
    "\n",
    "'''\n",
    "pattern = [{\"label\": \"NOUN\", \"pattern\": \"church\"}, \n",
    "            {\"label\": \"ORG\", \"pattern\": [{\"lower\": \"the\"}, {\"lower\": {\"IN\": [\"first\", \"second\", \"third\"]}}, {\"ORTH\": \"Estate\"}]}]\n",
    "'''\n",
    "\n",
    "# add the pattern to the matcher object\n",
    "ruler.add_patterns(pattern)\n",
    "\n",
    "# add the matcher object as a new pipe to the model\n",
    "nlp.add_pipe(ruler)\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "\n",
    "# create a spaCy object \n",
    "doc = nlp(u'GDP in developing countries such as Vietnam will continue growing at a high rate.'\n",
    "            u'Fruits such as apples. '\n",
    "            u'Cars such as Ferrari. '\n",
    "            u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million. '\n",
    "            u'By contrast, Sony sold only 7 thousand Walkman music players. '\n",
    "            u'credits will be allocated on 1 Jan of every year. '\n",
    "            u'carried forward up to one credit year. ')\n",
    "\n",
    "# print the entities in the sentenced after adding the EntityRuler matcher\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for sent in doc.sents:\n",
    "    docx = nlp(sent.text)\n",
    "    if docx.ents:\n",
    "        displacy.render(docx, style='ent', jupyter=True)\n",
    "    else:\n",
    "        print(docx.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup - Reading HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('htmlWithTables.txt','r') as txt:\n",
    "    htmlText = txt.read()\n",
    "    soup = BeautifulSoup(htmlText, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content\n",
      "\n",
      "Header\n",
      "\n",
      "\n",
      "Contract Staff\n"
     ]
    }
   ],
   "source": [
    "# retrieve text of tags in HTML\n",
    "print(soup.h2.text)\n",
    "print(soup.head.text)\n",
    "print(soup.li.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "li: Contract Staff\n",
      "li: Temporary Staff\n"
     ]
    }
   ],
   "source": [
    "# retrieve all text of li tags in HTML\n",
    "for tag in soup.find_all('li'):\n",
    "    print(f'{tag.name}: {tag.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tier                   Length       Credits\n",
      "0     1  0 to 1 years of service     1 credits\n",
      "1     2  2 to 3 years of service    10 credits\n",
      "2     3  4 to 5 years of service   100 credits\n",
      "3     4  6 to 7 years of service  1000 credits\n",
      "\n",
      "\n",
      "Tier                             1\n",
      "Length     0 to 1 years of service\n",
      "Credits                  1 credits\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# create convert table into dataframe\n",
    "df = pd.read_html(htmlText, header = 0)\n",
    "\n",
    "firstTable = df[0]\n",
    "print(firstTable)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(firstTable.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple Doc object\n",
    "doc = nlp(htmlText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Challenges\n",
    "<ul>\n",
    "    <li>Current policies have alot of point forms. Some point forms are written in HTML, can be extracted using beautifulsoup but some are not. Some important content not in a proper english sentences e.g. containing a point forms</li>\n",
    "    <li>Will be difficult to extract information from tables, workaround is to display all tables in policy. But if the policy contains a large table or multiple tables, it will make the knowledge panel very big</li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
